export const metadata = {
    title: 'Wishcasting, The Plateau, and The Death of The API Model',
    date: '2025-03-04',
    description: 'Maybe both the labs and their models need grounding',
    hidden: true
}
import { Footnote, FootnoteContent } from '@/components/Footnote'

The release of DeepSeek R1 shocked the world in no small part because it proved that RL was easy. A competent base model and a freely-available set of premade tasks can have RLVR applied to it in basically any number of ways and result in a state-of-the-art release. My reaction was basically the same as everyone else's, with a twinge of "God, if I had spent less time screwing around with classifiers for critic models I would've had a demo of this in November".

In the month and a half since, a variety of tools, think-pieces, and demo runs have flooded the space. It has been proven at least a hundred times that RL can make Qwen 2.5 0.5B *very* good at GSM8K. As tools mature<Footnote index={1} /> and efficiency improvements allow us to do training runs on usably-large models, though, 